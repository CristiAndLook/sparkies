{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra cómo crear un RDD en Spark:\n",
    "\n",
    "# Diferentes formas de crear un RDD en Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sparkies').master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un RDD vacío\n",
    "rdd_1 = sc.emptyRDD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear un RDD con parallelize\n",
    "rdd_2 = sc.parallelize([1,2,3,4,5,6,7,8,9,10], 4)\n",
    "\n",
    "#Número de particiones\t\n",
    "rdd_2.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Número de elementos\n",
    "rdd_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra los elementos del RDD\n",
    "rdd_2.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8, 9, 10]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra los elementos del RDD por particiones\n",
    "rdd_2.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Así podemos crear', 'un RDD desde un', 'archivo de texto!!!']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear un RDD a partir de un fichero\n",
    "rdd_3 = sc.textFile(\"./work/sources/rdd_source.txt\")\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Col1='a', Col2=1),\n",
       " Row(Col1='b', Col2=2),\n",
       " Row(Col1='c', Col2=3),\n",
       " Row(Col1='d', Col2=4)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear un RDD a partir de un dataframe\n",
    "df = spark.createDataFrame([(\"a\", 1), (\"b\", 2), (\"c\",  3), (\"d\", 4)], [\"Col1\", \"Col2\"])\n",
    "rdd_5 = df.rdd\n",
    "\n",
    "#Muestra los elementos del RDD  \n",
    "rdd_5.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones en un RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando map\n",
    "rdd_4 = rdd_2.map(lambda x: x**2)\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando filter\n",
    "rdd_5 = rdd_2.filter(lambda x: x%2 == 0)\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_5.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 4, 3, 9, 4, 16, 5, 25, 6, 36, 7, 49, 8, 64, 9, 81, 10, 100]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando flatMap\n",
    "rdd_6 = rdd_2.flatMap(lambda x: (x, x**2))\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_6.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando coalesce\n",
    "#Reduce el número de particiones\n",
    "rdd_7 = rdd_2.coalesce(2)\n",
    "\n",
    "#Número de particiones\n",
    "rdd_7.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando repartition\n",
    "#Reduce el número de particiones\n",
    "rdd_8 = rdd_2.repartition(2)\n",
    "\n",
    "#Número de particiones\n",
    "rdd_8.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 30), (1, 25)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando reduceByKey\n",
    "rdd_9 = rdd_2.map(lambda x: (x%2, x)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_9.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cree un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL.\n",
    "lenguajes = sc.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PYTHON', 'R', 'C', 'SCALA', 'RUGBY', 'SQL']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenguajes_upper = lenguajes.map(lambda x: x.upper())\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "lenguajes_upper.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'r', 'c', 'scala', 'rugby', 'sql']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenguajes_lower = lenguajes.map(lambda x: x.lower())\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "lenguajes_lower.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 'Rugby']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenguajes_init_r = lenguajes.filter(lambda x: x.startswith(\"R\"))\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "lenguajes_init_r.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 22, 24, 26, 28, 30]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cree un RDD llamado pares que contenga los números pares existentes en el intervalo [20;30].\n",
    "pares = sc.parallelize(range(20,31)).filter(lambda x: x%2 == 0)\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "pares.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400, 484, 576, 676, 784, 900]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pares_sqrt = pares.map(lambda x: x**2)\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "pares_sqrt.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 400), (22, 484), (24, 576), (26, 676), (28, 784), (30, 900)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pares_list = pares.map(lambda x: (x, x**2))\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "pares_list.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 8000, 22, 10648, 24, 13824, 26, 17576, 28, 21952, 30, 27000]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pares_lista_2 = pares.flatMap(lambda x: (x, x**3))\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "pares_lista_2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acciones en un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando reduce y reduceByKey\n",
    "rdd_10 = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "#Suma de los elementos del RDD\n",
    "rdd_sum = rdd_10.reduce(lambda x,y: x+y)\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 17), (1, 5), (5, 21), (2, 9), (3, 13)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD usando reduceByKey\n",
    "rdd_11 = sc.parallelize([(1,2),(1,3),(2,4),(2,5),(3,6),(3,7),(4,8),(4,9),(5,10),(5,11)])\n",
    "\n",
    "#Suma de los elementos del RDD\n",
    "rdd_11.reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando count, take, max y saveAsTextFile\n",
    "#Número de elementos del RDD\n",
    "rdd_11.count()\n",
    "\n",
    "#Muestra los 3 primeros elementos del RDD\n",
    "rdd_11.take(3)\n",
    "\n",
    "#Máximo del RDD\n",
    "rdd_11.max()\n",
    "\n",
    "#Mínimo del RDD\n",
    "rdd_11.min()\n",
    "\n",
    "#Muestra los elementos del RDD\n",
    "rdd_11.collect()\n",
    "\n",
    "#Guarda el RDD en un fichero\n",
    "rdd_11.saveAsTextFile(\"./work/results/rdd_11.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspectos avanzados sobre RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "#Almacenamiento en caché\n",
    "rdd_12 = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "#Almacenamiento en caché\n",
    "rdd_12.persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Particionado del RDD\n",
    "#Ejemplo de como funciona el particionado\n",
    "rdd_13 = sc.parallelize(['x', 'y', 'z'])\n",
    "\n",
    "#Número de particiones\n",
    "rdd_13.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indice de la partición = hash(key) % numPartitions\n",
    "# hash('x') = 120\n",
    "# hash('y') = 121\n",
    "# hash('z') = 122\n",
    "# hash('x') % 4 = 0\n",
    "# hash('y') % 4 = 1\n",
    "# hash('z') % 4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadcast variables\n",
    "#Crea una variable broadcast\n",
    "broadcast_var = sc.broadcast([1,2,3,4,5])\n",
    "\n",
    "#Muestra los elementos de la variable broadcast\n",
    "broadcast_var.value\n",
    "\n",
    "#Accede a los elementos de la variable broadcast\n",
    "broadcast_var.value[0]\n",
    "\n",
    "#Destruye la variable broadcast\n",
    "broadcast_var.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acumuladores\n",
    "#Crea un acumulador\n",
    "acumulador = sc.accumulator(0)\n",
    "\n",
    "#Muestra el valor del acumulador\n",
    "acumulador.value\n",
    "\n",
    "#Incrementa el valor del acumulador\n",
    "acumulador.add(1)\n",
    "\n",
    "#Usa foreach para incrementar el valor del acumulador\n",
    "rdd_14 = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
    "rdd_14.foreach(lambda x: acumulador.add(x))\n",
    "\n",
    "#Muestra el valor del acumulador\n",
    "acumulador.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
